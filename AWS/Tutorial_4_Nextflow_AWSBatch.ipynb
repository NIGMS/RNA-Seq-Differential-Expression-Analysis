{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cfa998-06b6-4b42-ae3a-b4e011750d31",
   "metadata": {},
   "source": [
    "# RNA-Seq Analysis using Nextflow and AWS Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126cb07-34ee-4780-838f-872015a882b3",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ea992-faa6-4705-8384-eb5d81f5daff",
   "metadata": {},
   "source": [
    "This short tutorial demonstrates how to run an RNA-Seq workflow using a prokaryotic data set. Steps in the workflow include read trimming, read QC, read mapping, and counting mapped reads per gene to quantitate gene expression. This tutorial uses a popular workflow manager called [Nextflow](https://www.nextflow.io) run via [AWS Batch](https://aws.amazon.com/batch/). If you completed the other tutorials in this repo, you will see that it is similar to Tutorial 2, but instead of running Snakemake locally, we switch to Nextflow and run it using Batch. \n",
    "\n",
    "AWS Batch will create the needed permissions, roles and resources to run Nextflow in a serverless manner. You can set up AWS Batch manually or deploy it **automatically** with a stack template. The Launch Stack button below will take you to the cloud formation create stack webpage with the template with required resources already linked. \n",
    "\n",
    "If you prefer to skip manual deployment and deploy automatically in the cloud, click the Launch Stack button below. For a walkthrough of the screens during automatic deployment please click [here](https://github.com/NIGMS/NIGMS-Sandbox/blob/main/docs/HowToLaunchAWSBatch.md). The deployment should take ~5 min and then the resources will be ready for use. \n",
    "\n",
    "[![Launch Stack](images/LaunchStack.jpg)](https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=aws-batch-nigms&templateURL=https://nigms-sandbox.s3.us-east-1.amazonaws.com/cf-templates/AWSBatch_template.yaml )\n",
    "\n",
    "\n",
    "Before begining this tutorial, if you do not have required roles, policies, permissions or compute environment and would like to **manually** set those up please click [here](https://github.com/NIGMS/NIGMS-Sandbox/blob/main/docs/AWS-Batch-Setup.md) to set that up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d718a8",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "#### Python requirements\n",
    "+ Python >= 3.8\n",
    "\n",
    "#### AWS requirements\n",
    "+ Please ensure you have a VPC, subnets, and security group set up before running this tutorial.\n",
    "+ Role with AdministratorAccess, AmazonSageMakerFullAccess, S3 access and AWSBatchServiceRole.\n",
    "+ Instance Role with AmazonECS_FullAccess, AmazonEC2ContainerRegistryFullAccess, and S3 access.\n",
    "+ If you do not have the required set-up for AWS Batch please follow this tutorial [here](https://github.com/STRIDES/NIHCloudLabAWS/blob/zbyosufzai-awsbatch-1/notebooks/AWSBatch/Intro_AWS_Batch.ipynb#install_nextflow). ***When making the instance role, make another for SageMaker notebooks with the following permissions: AdminstratorAccess, AmazonEC2ContainerRegistryFullAccess, AmazonECS_FullAccess, AmazonS3FullAccess, AmazonSageMakerFullAccess, and AWSBatchServiceRole.***\n",
    "It is recommended that specific permission to folders are added through inline policy. An example of the JSON is below:\n",
    "\n",
    "<pre>\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowSageMakerS3Access\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetBucketLocation\",\n",
    "                \"s3:CreateBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::batch-bucket\",\n",
    "                \"arn:aws:s3:::batch-bucket/*\",\n",
    "                \"arn:aws:s3:::nigms-sandbox-healthomics\",\n",
    "                \"arn:aws:s3:::nigms-sandbox-healthomics/*\",\n",
    "                \"arn:aws:s3:::ngi-igenomes\",\n",
    "                \"arn:aws:s3:::ngi-igenomes/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "</pre>\n",
    "For AWS bucket naming conventions, please click [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940d3ca",
   "metadata": {},
   "source": [
    "### Step 1. Install required dependencies, update paths and create a new S3 Bucket to store input and output files (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# Get account ID and region \n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb43e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable names \n",
    "# These variables should come from the Intro AWS Batch tutorial (or leave as-is if using the launch stack button)\n",
    "BUCKET_NAME = \"aws-batch-nigms-batch-bucket-\" + account_id\n",
    "INPUT_FOLDER = 'nigms-sandbox/me-inbre-rnaseq-pipelinev2'\n",
    "AWS_QUEUE = 'aws-batch-nigms-JobQueue'\n",
    "AWS_REGION = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Nextflow\n",
    "! mamba install -y -c conda-forge -c bioconda nextflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import relevant libraries\n",
    "# Created using this https://github.com/STRIDES/NIHCloudLabAWS/blob/zbyosufzai-awsbatch-1/notebooks/AWSBatch/Intro_AWS_Batch.ipynb#install_nextflow\n",
    "#Run if you don't have Java installed\n",
    "! sudo apt update\n",
    "! sudo apt-get install default-jdk -y\n",
    "! java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install nexflow, make it exceutable, and update it\n",
    "! curl https://get.nextflow.io | bash\n",
    "! chmod +x nextflow\n",
    "! ./nextflow self-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace batch bucket name in nextflow configuration file\n",
    "! sed -i \"s/aws-batch-nigms-batch-bucket-/$BUCKET_NAME/g\" nextflow.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace job queue name in configuration file \n",
    "! sed -i \"s/aws-batch-nigms-JobQueue/$AWS_QUEUE/g\" nextflow.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09770029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the region placeholder with the region you are in \n",
    "! sed -i \"s/aws-region/$AWS_REGION/g\" nextflow.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6424c54-108f-459e-8f14-f2866bfc0141",
   "metadata": {},
   "source": [
    "### Step 2. Enable AWS Batch for the nextflow script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb4617-b98c-41b6-995d-711d2f722cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run nextflow script with parameters \n",
    "! ./nextflow run main.nf --input s3://$INPUT_FOLDER/data/raw_fastqSub/samplesheet.csv -profile docker,awsbatch -c nextflow.config --awsqueue  $AWS_QUEUE --awsregion $AWS_REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ab630-955d-43d1-bc43-c7b3e701ed04",
   "metadata": {},
   "source": [
    "### STEP 3: Report the top 10 most highly expressed genes in the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ddf88-e1d9-443f-a423-e1f85ff604a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View output files in folder\n",
    "! aws s3 ls s3://$BUCKET_NAME/nextflow_output/data/quant --recursive | cut -c32-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d0630-1d85-4625-bc04-036aae11ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output to here \n",
    "! aws s3 sync s3://$BUCKET_NAME/nextflow_output/data/quant quant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c221b-45ce-47fb-a8e2-29ceee0e296a",
   "metadata": {},
   "source": [
    "View the top 10 most highly expressed genes in the double lysogen sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ce8d5-4b96-4e97-88ed-44e8e85f4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for samp in quant/*/quant.sf; \n",
    "    do echo $samp; \n",
    "    sort -nrk 5,5 quant/*/quant.sf | head -10; \n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33d41c-3444-4e15-944f-07a8625611b7",
   "metadata": {},
   "source": [
    "### STEP 4: Report the expression of a putative acyl-ACP desaturase (BB28_RS16545) that was downregulated in the double lysogen relative to wild-type\n",
    "A acyl-transferase was reported to be downregulated in the double lysogen as shown in the table of the top 20 upregulated and downregulated genes from the paper describing the study.\n",
    "![RNA-Seq workflow](images/table-cushman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c0273-c7f1-4aee-bdf3-43d5773cf2fa",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cb07a-7c7e-430a-9781-600553b3a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for samp in quant/*/quant.sf; do echo $samp; \n",
    "    echo Name    Length  EffectiveLength TPM     NumReads;\n",
    "    grep 'BB28_RS16545' quant/*/quant.sf; \n",
    "    done"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
